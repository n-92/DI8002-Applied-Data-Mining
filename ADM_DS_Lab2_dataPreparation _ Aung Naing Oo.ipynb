{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Applied Data Mining</center></h3>\n",
    "<h1><center>Lab 2: Data Preparation</center></h1>\n",
    "\n",
    "\n",
    "The objective of the second lab is to implement some of the methods that we have covered in the lecture to prepare the data for the modeling part. In this lab, you also have some tasks to do. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Import Data\n",
    "The examples provided in this lab will use the following datasets. Download them and store them on the same path as your notebook is.\n",
    "- __Building permits__: A building permit is an official approval document issued by a governmental agency that allows you or your contractor to proceed with a construction or remodeling project on one's property. To get more information about this dataset look [here](https://www.kaggle.com/aparnashastry/building-permit-applications-data)\n",
    "- __Iris dataset__: gives the measurements in centimeters of the variables sepal length and width and petal length and width for 150 iris flowers from three different species. Download data from blackboard or [here](https://www.kaggle.com/saurabh00007/iriscsv/download)\n",
    "- __AUS weather dataset__: The data set contains daily weather observations from numerous Australian weather stations. The target variable RainTomorrow means: Did it rain the next day? Yes or No. Download data from blackboard.\n",
    "\n",
    "- __NSL_KDD dataset__: contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment. You can download this data from blackboard. To get more information about this dataset look [here](https://www.unb.ca/cic/datasets/nsl.html)\n",
    "\n",
    "Download data from blackboard or [here](https://drive.google.com/open?id=1bYwUzFzrgCJ1lyjFVf3f4nyatBaMlcxS)\n",
    "<img src=\"sepal vs petal.jpeg\" />\n",
    "\n",
    "    Using the below codes you can import the data and see some information about the data:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198900 entries, 0 to 198899\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   Permit Number                           198900 non-null  object \n",
      " 1   Permit Type                             198900 non-null  int64  \n",
      " 2   Permit Type Definition                  198900 non-null  object \n",
      " 3   Permit Creation Date                    198900 non-null  object \n",
      " 4   Block                                   198900 non-null  object \n",
      " 5   Lot                                     198900 non-null  object \n",
      " 6   Street Number                           198900 non-null  int64  \n",
      " 7   Street Number Suffix                    2216 non-null    object \n",
      " 8   Street Name                             198900 non-null  object \n",
      " 9   Street Suffix                           196132 non-null  object \n",
      " 10  Unit                                    29479 non-null   float64\n",
      " 11  Unit Suffix                             1961 non-null    object \n",
      " 12  Description                             198610 non-null  object \n",
      " 13  Current Status                          198900 non-null  object \n",
      " 14  Current Status Date                     198900 non-null  object \n",
      " 15  Filed Date                              198900 non-null  object \n",
      " 16  Issued Date                             183960 non-null  object \n",
      " 17  Completed Date                          97191 non-null   object \n",
      " 18  First Construction Document Date        183954 non-null  object \n",
      " 19  Structural Notification                 6922 non-null    object \n",
      " 20  Number of Existing Stories              156116 non-null  float64\n",
      " 21  Number of Proposed Stories              156032 non-null  float64\n",
      " 22  Voluntary Soft-Story Retrofit           35 non-null      object \n",
      " 23  Fire Only Permit                        18827 non-null   object \n",
      " 24  Permit Expiration Date                  147020 non-null  object \n",
      " 25  Estimated Cost                          160834 non-null  float64\n",
      " 26  Revised Cost                            192834 non-null  float64\n",
      " 27  Existing Use                            157786 non-null  object \n",
      " 28  Existing Units                          147362 non-null  float64\n",
      " 29  Proposed Use                            156461 non-null  object \n",
      " 30  Proposed Units                          147989 non-null  float64\n",
      " 31  Plansets                                161591 non-null  float64\n",
      " 32  TIDF Compliance                         2 non-null       object \n",
      " 33  Existing Construction Type              155534 non-null  float64\n",
      " 34  Existing Construction Type Description  155534 non-null  object \n",
      " 35  Proposed Construction Type              155738 non-null  float64\n",
      " 36  Proposed Construction Type Description  155738 non-null  object \n",
      " 37  Site Permit                             5359 non-null    object \n",
      " 38  Supervisor District                     197183 non-null  float64\n",
      " 39  Neighborhoods - Analysis Boundaries     197175 non-null  object \n",
      " 40  Zipcode                                 197184 non-null  float64\n",
      " 41  Location                                197200 non-null  object \n",
      " 42  Record ID                               198900 non-null  int64  \n",
      "dtypes: float64(12), int64(3), object(28)\n",
      "memory usage: 65.3+ MB\n",
      "Hi\n"
     ]
    }
   ],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "mydata_bpermits = pd.read_csv('lab2_data/Building_Permits.csv',low_memory=False)\n",
    "mydata_bpermits.head()\n",
    "mydata_bpermits.info()\n",
    "\n",
    "print('Hi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Number Suffix</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing Construction Type</th>\n",
       "      <th>Existing Construction Type Description</th>\n",
       "      <th>Proposed Construction Type</th>\n",
       "      <th>Proposed Construction Type Description</th>\n",
       "      <th>Site Permit</th>\n",
       "      <th>Supervisor District</th>\n",
       "      <th>Neighborhoods - Analysis Boundaries</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Location</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201505065519</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>05/06/2015</td>\n",
       "      <td>0326</td>\n",
       "      <td>023</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.785719256680785, -122.40852313194863)</td>\n",
       "      <td>1380611233945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201604195146</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>04/19/2016</td>\n",
       "      <td>0306</td>\n",
       "      <td>007</td>\n",
       "      <td>440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geary</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.78733980600732, -122.41063199757738)</td>\n",
       "      <td>1420164406718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201605278609</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>0595</td>\n",
       "      <td>203</td>\n",
       "      <td>1647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Russian Hill</td>\n",
       "      <td>94109.0</td>\n",
       "      <td>(37.7946573324287, -122.42232562979227)</td>\n",
       "      <td>1424856504716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201611072166</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>0156</td>\n",
       "      <td>011</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>94109.0</td>\n",
       "      <td>(37.79595867909168, -122.41557405519474)</td>\n",
       "      <td>1443574295566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201611283529</td>\n",
       "      <td>6</td>\n",
       "      <td>demolitions</td>\n",
       "      <td>11/28/2016</td>\n",
       "      <td>0342</td>\n",
       "      <td>001</td>\n",
       "      <td>950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.78315261897309, -122.40950883997789)</td>\n",
       "      <td>144548169992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Permit Number  Permit Type            Permit Type Definition  \\\n",
       "0  201505065519            4                      sign - erect   \n",
       "1  201604195146            4                      sign - erect   \n",
       "2  201605278609            3  additions alterations or repairs   \n",
       "3  201611072166            8            otc alterations permit   \n",
       "4  201611283529            6                       demolitions   \n",
       "\n",
       "  Permit Creation Date Block  Lot  Street Number Street Number Suffix  \\\n",
       "0           05/06/2015  0326  023            140                  NaN   \n",
       "1           04/19/2016  0306  007            440                  NaN   \n",
       "2           05/27/2016  0595  203           1647                  NaN   \n",
       "3           11/07/2016  0156  011           1230                  NaN   \n",
       "4           11/28/2016  0342  001            950                  NaN   \n",
       "\n",
       "  Street Name Street Suffix  ...  Existing Construction Type  \\\n",
       "0       Ellis            St  ...                         3.0   \n",
       "1       Geary            St  ...                         3.0   \n",
       "2     Pacific            Av  ...                         1.0   \n",
       "3     Pacific            Av  ...                         5.0   \n",
       "4      Market            St  ...                         3.0   \n",
       "\n",
       "  Existing Construction Type Description Proposed Construction Type  \\\n",
       "0                          constr type 3                        NaN   \n",
       "1                          constr type 3                        NaN   \n",
       "2                          constr type 1                        1.0   \n",
       "3                         wood frame (5)                        5.0   \n",
       "4                          constr type 3                        NaN   \n",
       "\n",
       "  Proposed Construction Type Description Site Permit Supervisor District  \\\n",
       "0                                    NaN         NaN                 3.0   \n",
       "1                                    NaN         NaN                 3.0   \n",
       "2                          constr type 1         NaN                 3.0   \n",
       "3                         wood frame (5)         NaN                 3.0   \n",
       "4                                    NaN         NaN                 6.0   \n",
       "\n",
       "  Neighborhoods - Analysis Boundaries  Zipcode  \\\n",
       "0                          Tenderloin  94102.0   \n",
       "1                          Tenderloin  94102.0   \n",
       "2                        Russian Hill  94109.0   \n",
       "3                            Nob Hill  94109.0   \n",
       "4                          Tenderloin  94102.0   \n",
       "\n",
       "                                    Location      Record ID  \n",
       "0  (37.785719256680785, -122.40852313194863)  1380611233945  \n",
       "1   (37.78733980600732, -122.41063199757738)  1420164406718  \n",
       "2    (37.7946573324287, -122.42232562979227)  1424856504716  \n",
       "3   (37.79595867909168, -122.41557405519474)  1443574295566  \n",
       "4   (37.78315261897309, -122.40950883997789)   144548169992  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata_bpermits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Handling Missing Values\n",
    "First, we need to make sure that whether the data consists missing values or not?\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Permit Number                             198900\n",
       "Permit Type                               198900\n",
       "Permit Type Definition                    198900\n",
       "Permit Creation Date                      198900\n",
       "Block                                     198900\n",
       "Lot                                       198900\n",
       "Street Number                             198900\n",
       "Street Number Suffix                      198900\n",
       "Street Name                               198900\n",
       "Street Suffix                             198900\n",
       "Unit                                      198900\n",
       "Unit Suffix                               198900\n",
       "Description                               198900\n",
       "Current Status                            198900\n",
       "Current Status Date                       198900\n",
       "Filed Date                                198900\n",
       "Issued Date                               198900\n",
       "Completed Date                            198900\n",
       "First Construction Document Date          198900\n",
       "Structural Notification                   198900\n",
       "Number of Existing Stories                198900\n",
       "Number of Proposed Stories                198900\n",
       "Voluntary Soft-Story Retrofit             198900\n",
       "Fire Only Permit                          198900\n",
       "Permit Expiration Date                    198900\n",
       "Estimated Cost                            198900\n",
       "Revised Cost                              198900\n",
       "Existing Use                              198900\n",
       "Existing Units                            198900\n",
       "Proposed Use                              198900\n",
       "Proposed Units                            198900\n",
       "Plansets                                  198900\n",
       "TIDF Compliance                           198900\n",
       "Existing Construction Type                198900\n",
       "Existing Construction Type Description    198900\n",
       "Proposed Construction Type                198900\n",
       "Proposed Construction Type Description    198900\n",
       "Site Permit                               198900\n",
       "Supervisor District                       198900\n",
       "Neighborhoods - Analysis Boundaries       198900\n",
       "Zipcode                                   198900\n",
       "Location                                  198900\n",
       "Record ID                                 198900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata_bpermits.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Using the below code you find the features which have missing values..   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Street Number Suffix has 196684 records (98.89%) with missing values\n",
      "Variable Street Suffix has 2768 records (1.39%) with missing values\n",
      "Variable Unit has 169421 records (85.18%) with missing values\n",
      "Variable Unit Suffix has 196939 records (99.01%) with missing values\n",
      "Variable Description has 290 records (0.15%) with missing values\n",
      "Variable Issued Date has 14940 records (7.51%) with missing values\n",
      "Variable Completed Date has 101709 records (51.14%) with missing values\n",
      "Variable First Construction Document Date has 14946 records (7.51%) with missing values\n",
      "Variable Structural Notification has 191978 records (96.52%) with missing values\n",
      "Variable Number of Existing Stories has 42784 records (21.51%) with missing values\n",
      "Variable Number of Proposed Stories has 42868 records (21.55%) with missing values\n",
      "Variable Voluntary Soft-Story Retrofit has 198865 records (99.98%) with missing values\n",
      "Variable Fire Only Permit has 180073 records (90.53%) with missing values\n",
      "Variable Permit Expiration Date has 51880 records (26.08%) with missing values\n",
      "Variable Estimated Cost has 38066 records (19.14%) with missing values\n",
      "Variable Revised Cost has 6066 records (3.05%) with missing values\n",
      "Variable Existing Use has 41114 records (20.67%) with missing values\n",
      "Variable Existing Units has 51538 records (25.91%) with missing values\n",
      "Variable Proposed Use has 42439 records (21.34%) with missing values\n",
      "Variable Proposed Units has 50911 records (25.60%) with missing values\n",
      "Variable Plansets has 37309 records (18.76%) with missing values\n",
      "Variable TIDF Compliance has 198898 records (100.00%) with missing values\n",
      "Variable Existing Construction Type has 43366 records (21.80%) with missing values\n",
      "Variable Existing Construction Type Description has 43366 records (21.80%) with missing values\n",
      "Variable Proposed Construction Type has 43162 records (21.70%) with missing values\n",
      "Variable Proposed Construction Type Description has 43162 records (21.70%) with missing values\n",
      "Variable Site Permit has 193541 records (97.31%) with missing values\n",
      "Variable Supervisor District has 1717 records (0.86%) with missing values\n",
      "Variable Neighborhoods - Analysis Boundaries has 1725 records (0.87%) with missing values\n",
      "Variable Zipcode has 1716 records (0.86%) with missing values\n",
      "Variable Location has 1700 records (0.85%) with missing values\n",
      "In total, there are 31 variables with missing values\n"
     ]
    }
   ],
   "source": [
    "mydata_bpermits.shape\n",
    "\n",
    "vars_with_missing = []\n",
    "\n",
    "for f in mydata_bpermits.columns:\n",
    "    #missings = mydata[f].isnull().count()\n",
    "    missings = sum(mydata_bpermits[f].isnull())\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/mydata_bpermits.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### Removing Missing Values\n",
    "Try to remove the features which have many missing values!\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Street Number Suffix has 196684 records (98.89%) with missing values\n",
      "Variable Street Suffix has 2768 records (1.39%) with missing values\n",
      "Variable Unit has 169421 records (85.18%) with missing values\n",
      "Variable Unit Suffix has 196939 records (99.01%) with missing values\n",
      "Variable Description has 290 records (0.15%) with missing values\n",
      "Variable Issued Date has 14940 records (7.51%) with missing values\n",
      "Variable Completed Date has 101709 records (51.14%) with missing values\n",
      "Variable First Construction Document Date has 14946 records (7.51%) with missing values\n",
      "Variable Structural Notification has 191978 records (96.52%) with missing values\n",
      "Variable Number of Existing Stories has 42784 records (21.51%) with missing values\n",
      "Variable Number of Proposed Stories has 42868 records (21.55%) with missing values\n",
      "Variable Voluntary Soft-Story Retrofit has 198865 records (99.98%) with missing values\n",
      "Variable Fire Only Permit has 180073 records (90.53%) with missing values\n",
      "Variable Permit Expiration Date has 51880 records (26.08%) with missing values\n",
      "Variable Estimated Cost has 38066 records (19.14%) with missing values\n",
      "Variable Revised Cost has 6066 records (3.05%) with missing values\n",
      "Variable Existing Use has 41114 records (20.67%) with missing values\n",
      "Variable Existing Units has 51538 records (25.91%) with missing values\n",
      "Variable Proposed Use has 42439 records (21.34%) with missing values\n",
      "Variable Proposed Units has 50911 records (25.60%) with missing values\n",
      "Variable Plansets has 37309 records (18.76%) with missing values\n",
      "Variable TIDF Compliance has 198898 records (100.00%) with missing values\n",
      "Variable Existing Construction Type has 43366 records (21.80%) with missing values\n",
      "Variable Existing Construction Type Description has 43366 records (21.80%) with missing values\n",
      "Variable Proposed Construction Type has 43162 records (21.70%) with missing values\n",
      "Variable Proposed Construction Type Description has 43162 records (21.70%) with missing values\n",
      "Variable Site Permit has 193541 records (97.31%) with missing values\n",
      "Variable Supervisor District has 1717 records (0.86%) with missing values\n",
      "Variable Neighborhoods - Analysis Boundaries has 1725 records (0.87%) with missing values\n",
      "Variable Zipcode has 1716 records (0.86%) with missing values\n",
      "Variable Location has 1700 records (0.85%) with missing values\n"
     ]
    }
   ],
   "source": [
    "category_with_missing = []\n",
    "missings = 0\n",
    "\n",
    "for f in mydata_bpermits:\n",
    "    #missings = mydata[f].isnull().count()\n",
    "    missings = sum(mydata_bpermits[f].isnull())\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/mydata_bpermits.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "\n",
    "mydata_bpermits=mydata_bpermits.drop(['Street Number Suffix','Fire Only Permit'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198900, 41)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata_bpermits.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Removing Missing Values\n",
    "You can even remove all the columns which have missing values\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198900, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytestdata=mydata_bpermits.copy()\n",
    "mytestdata=mytestdata.dropna(axis=1)\n",
    "mytestdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing values with Mean and Mode. We apply these two methods on two numrical features as follows:   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcolumns=mydata_bpermits[['Zipcode','Revised Cost']]\n",
    "#Mean\n",
    "mean_values=newcolumns['Revised Cost'].mean()\n",
    "newcolumns['Revised Cost']=newcolumns['Revised Cost'].fillna(mean_values)\n",
    "#Mode\n",
    "most_frequent_values=newcolumns['Zipcode'].mode()[0]\n",
    "newcolumns['Zipcode']=newcolumns['Zipcode'].fillna(most_frequent_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Zipcode   Revised Cost\n",
      "0       94102.0    4000.000000\n",
      "1       94102.0     500.000000\n",
      "2       94109.0  132856.186492\n",
      "3       94109.0    2000.000000\n",
      "4       94102.0  100000.000000\n",
      "...         ...            ...\n",
      "198895  94110.0       1.000000\n",
      "198896  94110.0    5000.000000\n",
      "198897  94110.0       1.000000\n",
      "198898  94110.0       1.000000\n",
      "198899  94110.0       1.000000\n",
      "\n",
      "[198900 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#print the colun to make sure that have filled the missing values correctly:\n",
    "print(newcolumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Try to handle missing values for categorical valriables?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Existing Construction Type has 43366 records (21.80%) with missing values\n",
      "Variable Proposed Use has 42439 records (21.34%) with missing values\n"
     ]
    }
   ],
   "source": [
    "#Fill the missing rows for ['Existing Construction Type','Proposed Use'] with the most common category\n",
    "\n",
    "categorical_columns = mydata_bpermits[['Existing Construction Type','Proposed Use']]\n",
    "\n",
    "for f in categorical_columns:\n",
    "    missings = sum(categorical_columns[f].isnull())\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/mydata_bpermits.shape[0]\n",
    "\n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "\n",
    "\n",
    "most_frequent_values = categorical_columns['Existing Construction Type'].mode()[0]\n",
    "newcolumns['Existing Construction Type'] = categorical_columns['Existing Construction Type'].fillna(most_frequent_values)\n",
    "\n",
    "most_frequent_values = categorical_columns['Proposed Use'].mode()[0]\n",
    "newcolumns['Proposed Use'] = categorical_columns['Proposed Use'].fillna(most_frequent_values)\n",
    "\n",
    "#Repeat the same for other missing categorical columns with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Zipcode   Revised Cost  Existing Construction Type       Proposed Use\n",
      "0       94102.0    4000.000000                         3.0  1 family dwelling\n",
      "1       94102.0     500.000000                         3.0  1 family dwelling\n",
      "2       94109.0  132856.186492                         1.0       retail sales\n",
      "3       94109.0    2000.000000                         5.0  1 family dwelling\n",
      "4       94102.0  100000.000000                         3.0  1 family dwelling\n",
      "...         ...            ...                         ...                ...\n",
      "198895  94110.0       1.000000                         5.0  1 family dwelling\n",
      "198896  94110.0    5000.000000                         5.0         apartments\n",
      "198897  94110.0       1.000000                         5.0  1 family dwelling\n",
      "198898  94110.0       1.000000                         5.0  1 family dwelling\n",
      "198899  94110.0       1.000000                         5.0  1 family dwelling\n",
      "\n",
      "[198900 rows x 4 columns]\n",
      "Variable Zipcode has 0 records (0.00%) with missing values\n",
      "Variable Revised Cost has 0 records (0.00%) with missing values\n",
      "Variable Existing Construction Type has 0 records (0.00%) with missing values\n",
      "Variable Proposed Use has 0 records (0.00%) with missing values\n"
     ]
    }
   ],
   "source": [
    "print(newcolumns)\n",
    "vars_with_missing = []\n",
    "missings = 0\n",
    "missings_perc = 0\n",
    "\n",
    "#Check the changes after handling missing categorical values. If no output means, no missing values in data. \n",
    "for f in newcolumns:\n",
    "    missings = sum(newcolumns[f].isnull())\n",
    "    vars_with_missing.append(f)\n",
    "    missings_perc = missings/mydata_bpermits.shape[0]\n",
    "    print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation \n",
    "We intend to inerpolate some of the missing values 'NaN' by interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           4000.0\n",
      "1            500.0\n",
      "2           1250.0\n",
      "3           2000.0\n",
      "4         100000.0\n",
      "            ...   \n",
      "198895         1.0\n",
      "198896      5000.0\n",
      "198897         1.0\n",
      "198898         1.0\n",
      "198899         1.0\n",
      "Name: Revised Cost, Length: 198900, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#we copy the two columns again..\n",
    "newcolumns=mydata_bpermits[['Zipcode','Revised Cost']]\n",
    "\n",
    "#here we use a magic:)  'df.interpolade()' function.\n",
    "newcolumns['Revised Cost']=newcolumns['Revised Cost'].interpolate()\n",
    "\n",
    "#try to see what happened\n",
    "print(newcolumns['Revised Cost'])\n",
    "\n",
    "#interpolation function has other parameters which you can use based on your problem..\n",
    "#For example, by default the function is linear, but you can change it to polynominal, pad, etc. You can find \n",
    "#more info here: https://pandas.pydata.org/pandas-docs/version/0.24.2/reference/api/pandas.DataFrame.interpolate.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning the data\n",
    "In this part, we try to handle noisy data by binning method. \n",
    "Here is an example of \"ticket price\". As we dicsucsed during the class, sort the data: 4,8,15,21,21,24,25,28,34 , and then: \n",
    "\n",
    "1. Binning with Mean:\n",
    "    - Bin1: 9,9,9\n",
    "    - Bin2: 22,22,22\n",
    "    - Bin3: 29,29,29\n",
    "\n",
    "2. Binning with Boundaries:\n",
    "\n",
    "    - Bin1: 4,4,15\n",
    "    - Bin2: 21,21,24\n",
    "    - Bin3: 25,25,34\n",
    "    \n",
    "3. Binning with Median:\n",
    "\n",
    "    - Bin1: 8,8,8\n",
    "    - Bin2: 21,21,21\n",
    "    - Bin3: 28,28,28\n",
    "\n",
    "\n",
    "##### Instruction:\n",
    "Follow the below to do so:\n",
    "1. Import the iris data set:\n",
    "1. Sort the array of given data set.\n",
    "2. Divide the range into N (in this case 5) intervals, each containing the approximately same number of samples(Equal-depth    \n",
    "   partitioning).\n",
    "3. Store mean/ median/ boundaries in each row.\n",
    "First import the data and select only one column to apply your binding methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import csv\n",
    "import numpy as np   \n",
    "import math \n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn import datasets, linear_model, metrics  \n",
    "#importing the data\n",
    "mydata_iris=pd.read_csv('lab2_data/iris.csv')\n",
    "mydata_iris.describe()\n",
    "\n",
    "a = np.array(mydata_iris.iloc[:,2])\n",
    "b = np.zeros(150) \n",
    "  \n",
    " \n",
    "b=np.sort(a)  #sort the array \n",
    "  \n",
    "# we decided to have three bins\n",
    "bin1=np.zeros((30,5))  \n",
    "bin2=np.zeros((30,5)) \n",
    "bin3=np.zeros((30,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Binning with Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Mean: \n",
      " [[2.18 2.18 2.18 2.18 2.18]\n",
      " [2.34 2.34 2.34 2.34 2.34]\n",
      " [2.48 2.48 2.48 2.48 2.48]\n",
      " [2.52 2.52 2.52 2.52 2.52]\n",
      " [2.62 2.62 2.62 2.62 2.62]\n",
      " [2.7  2.7  2.7  2.7  2.7 ]\n",
      " [2.74 2.74 2.74 2.74 2.74]\n",
      " [2.8  2.8  2.8  2.8  2.8 ]\n",
      " [2.8  2.8  2.8  2.8  2.8 ]\n",
      " [2.86 2.86 2.86 2.86 2.86]\n",
      " [2.9  2.9  2.9  2.9  2.9 ]\n",
      " [2.96 2.96 2.96 2.96 2.96]\n",
      " [3.   3.   3.   3.   3.  ]\n",
      " [3.   3.   3.   3.   3.  ]\n",
      " [3.   3.   3.   3.   3.  ]\n",
      " [3.   3.   3.   3.   3.  ]\n",
      " [3.04 3.04 3.04 3.04 3.04]\n",
      " [3.1  3.1  3.1  3.1  3.1 ]\n",
      " [3.1  3.1  3.1  3.1  3.1 ]\n",
      " [3.2  3.2  3.2  3.2  3.2 ]\n",
      " [3.2  3.2  3.2  3.2  3.2 ]\n",
      " [3.24 3.24 3.24 3.24 3.24]\n",
      " [3.32 3.32 3.32 3.32 3.32]\n",
      " [3.4  3.4  3.4  3.4  3.4 ]\n",
      " [3.4  3.4  3.4  3.4  3.4 ]\n",
      " [3.48 3.48 3.48 3.48 3.48]\n",
      " [3.56 3.56 3.56 3.56 3.56]\n",
      " [3.74 3.74 3.74 3.74 3.74]\n",
      " [3.82 3.82 3.82 3.82 3.82]\n",
      " [4.12 4.12 4.12 4.12 4.12]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "# Binning with mean \n",
    "for i in range (0,150,5): \n",
    "    k=int(i/5) \n",
    "    mean=(b[i] + b[i+1] + b[i+2] + b[i+3] + b[i+4])/5\n",
    "    for j in range(5): \n",
    "        bin1[k,j]=mean \n",
    "print(\"Bin Mean: \\n\",bin1) \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Binning with Boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Boundaries: \n",
      " [[2.  2.3 2.3 2.3 2.3]\n",
      " [2.3 2.3 2.3 2.4 2.4]\n",
      " [2.4 2.5 2.5 2.5 2.5]\n",
      " [2.5 2.5 2.5 2.5 2.6]\n",
      " [2.6 2.6 2.6 2.6 2.7]\n",
      " [2.7 2.7 2.7 2.7 2.7]\n",
      " [2.7 2.7 2.7 2.8 2.8]\n",
      " [2.8 2.8 2.8 2.8 2.8]\n",
      " [2.8 2.8 2.8 2.8 2.8]\n",
      " [2.8 2.8 2.9 2.9 2.9]\n",
      " [2.9 2.9 2.9 2.9 2.9]\n",
      " [2.9 2.9 3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.1 3.1]\n",
      " [3.1 3.1 3.1 3.1 3.1]\n",
      " [3.1 3.1 3.1 3.1 3.1]\n",
      " [3.2 3.2 3.2 3.2 3.2]\n",
      " [3.2 3.2 3.2 3.2 3.2]\n",
      " [3.2 3.2 3.2 3.3 3.3]\n",
      " [3.3 3.3 3.3 3.3 3.4]\n",
      " [3.4 3.4 3.4 3.4 3.4]\n",
      " [3.4 3.4 3.4 3.4 3.4]\n",
      " [3.4 3.5 3.5 3.5 3.5]\n",
      " [3.5 3.5 3.6 3.6 3.6]\n",
      " [3.7 3.7 3.7 3.8 3.8]\n",
      " [3.8 3.8 3.8 3.8 3.9]\n",
      " [3.9 3.9 3.9 4.4 4.4]]\n"
     ]
    }
   ],
   "source": [
    "# Bin boundaries \n",
    "for i in range (0,150,5): \n",
    "    k=int(i/5) \n",
    "    for j in range (5): \n",
    "        if (b[i+j]-b[i]) < (b[i+4]-b[i+j]): \n",
    "            bin2[k,j]=b[i] \n",
    "        else: \n",
    "            bin2[k,j]=b[i+4]        \n",
    "print(\"Bin Boundaries: \\n\",bin2) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Binning with Median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Median: \n",
      " [[2.2 2.2 2.2 2.2 2.2]\n",
      " [2.3 2.3 2.3 2.3 2.3]\n",
      " [2.5 2.5 2.5 2.5 2.5]\n",
      " [2.5 2.5 2.5 2.5 2.5]\n",
      " [2.6 2.6 2.6 2.6 2.6]\n",
      " [2.7 2.7 2.7 2.7 2.7]\n",
      " [2.7 2.7 2.7 2.7 2.7]\n",
      " [2.8 2.8 2.8 2.8 2.8]\n",
      " [2.8 2.8 2.8 2.8 2.8]\n",
      " [2.9 2.9 2.9 2.9 2.9]\n",
      " [2.9 2.9 2.9 2.9 2.9]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.  3.  3.  3.  3. ]\n",
      " [3.1 3.1 3.1 3.1 3.1]\n",
      " [3.1 3.1 3.1 3.1 3.1]\n",
      " [3.2 3.2 3.2 3.2 3.2]\n",
      " [3.2 3.2 3.2 3.2 3.2]\n",
      " [3.2 3.2 3.2 3.2 3.2]\n",
      " [3.3 3.3 3.3 3.3 3.3]\n",
      " [3.4 3.4 3.4 3.4 3.4]\n",
      " [3.4 3.4 3.4 3.4 3.4]\n",
      " [3.5 3.5 3.5 3.5 3.5]\n",
      " [3.6 3.6 3.6 3.6 3.6]\n",
      " [3.7 3.7 3.7 3.7 3.7]\n",
      " [3.8 3.8 3.8 3.8 3.8]\n",
      " [4.1 4.1 4.1 4.1 4.1]]\n"
     ]
    }
   ],
   "source": [
    "# Bin median \n",
    "for i in range (0,150,5): \n",
    "    k=int(i/5) \n",
    "    for j in range (5): \n",
    "        bin3[k,j]=b[i+2] \n",
    "print(\"Bin Median: \\n\",bin3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "#### Min-MaxScaler metod:\n",
    "The data transformation is given by:\n",
    "\n",
    "feature_std = (feature_x - feature_x.min(axis=0)) / (feature_x.max(axis=0) - feature_x.min(axis=0))\n",
    "feature_scaled = feature_std * (max - min) + min\n",
    "\n",
    "You can use the folwoing librry to do the normalization automatically:\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#min_max_scaler.fit_transform('your data')\n",
    "#min_max_scaler.fit_transform('your data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2\n",
    "Try to implement the normalization method on the iris data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Min Max Normalization - SepalLengthCm\tSepalWidthCm\tPetalLengthCm\tPetalWidthCm\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "After Normalization\n",
      "[[0.22222222 0.625      0.06779661 0.04166667]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.05084746 0.04166667]\n",
      " [0.08333333 0.45833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.66666667 0.06779661 0.04166667]\n",
      " [0.30555556 0.79166667 0.11864407 0.125     ]\n",
      " [0.08333333 0.58333333 0.06779661 0.08333333]\n",
      " [0.19444444 0.58333333 0.08474576 0.04166667]\n",
      " [0.02777778 0.375      0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.30555556 0.70833333 0.08474576 0.04166667]\n",
      " [0.13888889 0.58333333 0.10169492 0.04166667]\n",
      " [0.13888889 0.41666667 0.06779661 0.        ]\n",
      " [0.         0.41666667 0.01694915 0.        ]\n",
      " [0.41666667 0.83333333 0.03389831 0.04166667]\n",
      " [0.38888889 1.         0.08474576 0.125     ]\n",
      " [0.30555556 0.79166667 0.05084746 0.125     ]\n",
      " [0.22222222 0.625      0.06779661 0.08333333]\n",
      " [0.38888889 0.75       0.11864407 0.08333333]\n",
      " [0.22222222 0.75       0.08474576 0.08333333]\n",
      " [0.30555556 0.58333333 0.11864407 0.04166667]\n",
      " [0.22222222 0.70833333 0.08474576 0.125     ]\n",
      " [0.08333333 0.66666667 0.         0.04166667]\n",
      " [0.22222222 0.54166667 0.11864407 0.16666667]\n",
      " [0.13888889 0.58333333 0.15254237 0.04166667]\n",
      " [0.19444444 0.41666667 0.10169492 0.04166667]\n",
      " [0.19444444 0.58333333 0.10169492 0.125     ]\n",
      " [0.25       0.625      0.08474576 0.04166667]\n",
      " [0.25       0.58333333 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.10169492 0.04166667]\n",
      " [0.13888889 0.45833333 0.10169492 0.04166667]\n",
      " [0.30555556 0.58333333 0.08474576 0.125     ]\n",
      " [0.25       0.875      0.08474576 0.        ]\n",
      " [0.33333333 0.91666667 0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.19444444 0.5        0.03389831 0.04166667]\n",
      " [0.33333333 0.625      0.05084746 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.02777778 0.41666667 0.05084746 0.04166667]\n",
      " [0.22222222 0.58333333 0.08474576 0.04166667]\n",
      " [0.19444444 0.625      0.05084746 0.08333333]\n",
      " [0.05555556 0.125      0.05084746 0.08333333]\n",
      " [0.02777778 0.5        0.05084746 0.04166667]\n",
      " [0.19444444 0.625      0.10169492 0.20833333]\n",
      " [0.22222222 0.75       0.15254237 0.125     ]\n",
      " [0.13888889 0.41666667 0.06779661 0.08333333]\n",
      " [0.22222222 0.75       0.10169492 0.04166667]\n",
      " [0.08333333 0.5        0.06779661 0.04166667]\n",
      " [0.27777778 0.70833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.54166667 0.06779661 0.04166667]\n",
      " [0.75       0.5        0.62711864 0.54166667]\n",
      " [0.58333333 0.5        0.59322034 0.58333333]\n",
      " [0.72222222 0.45833333 0.66101695 0.58333333]\n",
      " [0.33333333 0.125      0.50847458 0.5       ]\n",
      " [0.61111111 0.33333333 0.61016949 0.58333333]\n",
      " [0.38888889 0.33333333 0.59322034 0.5       ]\n",
      " [0.55555556 0.54166667 0.62711864 0.625     ]\n",
      " [0.16666667 0.16666667 0.38983051 0.375     ]\n",
      " [0.63888889 0.375      0.61016949 0.5       ]\n",
      " [0.25       0.29166667 0.49152542 0.54166667]\n",
      " [0.19444444 0.         0.42372881 0.375     ]\n",
      " [0.44444444 0.41666667 0.54237288 0.58333333]\n",
      " [0.47222222 0.08333333 0.50847458 0.375     ]\n",
      " [0.5        0.375      0.62711864 0.54166667]\n",
      " [0.36111111 0.375      0.44067797 0.5       ]\n",
      " [0.66666667 0.45833333 0.57627119 0.54166667]\n",
      " [0.36111111 0.41666667 0.59322034 0.58333333]\n",
      " [0.41666667 0.29166667 0.52542373 0.375     ]\n",
      " [0.52777778 0.08333333 0.59322034 0.58333333]\n",
      " [0.36111111 0.20833333 0.49152542 0.41666667]\n",
      " [0.44444444 0.5        0.6440678  0.70833333]\n",
      " [0.5        0.33333333 0.50847458 0.5       ]\n",
      " [0.55555556 0.20833333 0.66101695 0.58333333]\n",
      " [0.5        0.33333333 0.62711864 0.45833333]\n",
      " [0.58333333 0.375      0.55932203 0.5       ]\n",
      " [0.63888889 0.41666667 0.57627119 0.54166667]\n",
      " [0.69444444 0.33333333 0.6440678  0.54166667]\n",
      " [0.66666667 0.41666667 0.6779661  0.66666667]\n",
      " [0.47222222 0.375      0.59322034 0.58333333]\n",
      " [0.38888889 0.25       0.42372881 0.375     ]\n",
      " [0.33333333 0.16666667 0.47457627 0.41666667]\n",
      " [0.33333333 0.16666667 0.45762712 0.375     ]\n",
      " [0.41666667 0.29166667 0.49152542 0.45833333]\n",
      " [0.47222222 0.29166667 0.69491525 0.625     ]\n",
      " [0.30555556 0.41666667 0.59322034 0.58333333]\n",
      " [0.47222222 0.58333333 0.59322034 0.625     ]\n",
      " [0.66666667 0.45833333 0.62711864 0.58333333]\n",
      " [0.55555556 0.125      0.57627119 0.5       ]\n",
      " [0.36111111 0.41666667 0.52542373 0.5       ]\n",
      " [0.33333333 0.20833333 0.50847458 0.5       ]\n",
      " [0.33333333 0.25       0.57627119 0.45833333]\n",
      " [0.5        0.41666667 0.61016949 0.54166667]\n",
      " [0.41666667 0.25       0.50847458 0.45833333]\n",
      " [0.19444444 0.125      0.38983051 0.375     ]\n",
      " [0.36111111 0.29166667 0.54237288 0.5       ]\n",
      " [0.38888889 0.41666667 0.54237288 0.45833333]\n",
      " [0.38888889 0.375      0.54237288 0.5       ]\n",
      " [0.52777778 0.375      0.55932203 0.5       ]\n",
      " [0.22222222 0.20833333 0.33898305 0.41666667]\n",
      " [0.38888889 0.33333333 0.52542373 0.5       ]\n",
      " [0.55555556 0.54166667 0.84745763 1.        ]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.77777778 0.41666667 0.83050847 0.83333333]\n",
      " [0.55555556 0.375      0.77966102 0.70833333]\n",
      " [0.61111111 0.41666667 0.81355932 0.875     ]\n",
      " [0.91666667 0.41666667 0.94915254 0.83333333]\n",
      " [0.16666667 0.20833333 0.59322034 0.66666667]\n",
      " [0.83333333 0.375      0.89830508 0.70833333]\n",
      " [0.66666667 0.20833333 0.81355932 0.70833333]\n",
      " [0.80555556 0.66666667 0.86440678 1.        ]\n",
      " [0.61111111 0.5        0.69491525 0.79166667]\n",
      " [0.58333333 0.29166667 0.72881356 0.75      ]\n",
      " [0.69444444 0.41666667 0.76271186 0.83333333]\n",
      " [0.38888889 0.20833333 0.6779661  0.79166667]\n",
      " [0.41666667 0.33333333 0.69491525 0.95833333]\n",
      " [0.58333333 0.5        0.72881356 0.91666667]\n",
      " [0.61111111 0.41666667 0.76271186 0.70833333]\n",
      " [0.94444444 0.75       0.96610169 0.875     ]\n",
      " [0.94444444 0.25       1.         0.91666667]\n",
      " [0.47222222 0.08333333 0.6779661  0.58333333]\n",
      " [0.72222222 0.5        0.79661017 0.91666667]\n",
      " [0.36111111 0.33333333 0.66101695 0.79166667]\n",
      " [0.94444444 0.33333333 0.96610169 0.79166667]\n",
      " [0.55555556 0.29166667 0.66101695 0.70833333]\n",
      " [0.66666667 0.54166667 0.79661017 0.83333333]\n",
      " [0.80555556 0.5        0.84745763 0.70833333]\n",
      " [0.52777778 0.33333333 0.6440678  0.70833333]\n",
      " [0.5        0.41666667 0.66101695 0.70833333]\n",
      " [0.58333333 0.33333333 0.77966102 0.83333333]\n",
      " [0.80555556 0.41666667 0.81355932 0.625     ]\n",
      " [0.86111111 0.33333333 0.86440678 0.75      ]\n",
      " [1.         0.75       0.91525424 0.79166667]\n",
      " [0.58333333 0.33333333 0.77966102 0.875     ]\n",
      " [0.55555556 0.33333333 0.69491525 0.58333333]\n",
      " [0.5        0.25       0.77966102 0.54166667]\n",
      " [0.94444444 0.41666667 0.86440678 0.91666667]\n",
      " [0.55555556 0.58333333 0.77966102 0.95833333]\n",
      " [0.58333333 0.45833333 0.76271186 0.70833333]\n",
      " [0.47222222 0.41666667 0.6440678  0.70833333]\n",
      " [0.72222222 0.45833333 0.74576271 0.83333333]\n",
      " [0.66666667 0.45833333 0.77966102 0.95833333]\n",
      " [0.72222222 0.45833333 0.69491525 0.91666667]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.69444444 0.5        0.83050847 0.91666667]\n",
      " [0.66666667 0.54166667 0.79661017 1.        ]\n",
      " [0.66666667 0.41666667 0.71186441 0.91666667]\n",
      " [0.55555556 0.20833333 0.6779661  0.75      ]\n",
      " [0.61111111 0.41666667 0.71186441 0.79166667]\n",
      " [0.52777778 0.58333333 0.74576271 0.91666667]\n",
      " [0.44444444 0.41666667 0.69491525 0.70833333]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TODO:\n",
    "Your code should be placed here...\n",
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "features = np.array(mydata_iris.iloc[:,1:5])\n",
    "\n",
    "print(\"Before Min Max Normalization - SepalLengthCm\tSepalWidthCm\tPetalLengthCm\tPetalWidthCm\")\n",
    "print(features)\n",
    "\n",
    "normalized_feature_width = min_max_scaler.fit_transform(features)\n",
    "print(\"After Normalization\")\n",
    "print(normalized_feature_width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Australian weather data set\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142193, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0           W           44.0          W  ...        22.0       1007.7   \n",
       "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
       "2         WSW           46.0          W  ...        30.0       1007.6   \n",
       "3          NE           24.0         SE  ...        16.0       1017.6   \n",
       "4           W           41.0        ENE  ...        33.0       1010.8   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
       "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
       "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
       "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
       "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
       "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the NSL-KDD data\n",
    "mydata_weather = pd.read_csv('lab2_data/weatherAUS.csv',low_memory=False)\n",
    "print(mydata_weather.shape)\n",
    "mydata_weather.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Conversion-\n",
    "#### Using Factorize, Label and One-hot Encding\n",
    "Factorization is a method that we can convert categoricsl data to numericl. This is usefull when your e.g., feature selection algorithm does not support categorical data. SO in this way first, you can transfer your data to numerical, then you can send it to feature selection function to select the most informative attributes. Below you see a very simple example of factoriztion:   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Location' 'WindGustDir' 'WindDir9am']\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "accomodation_data = [\"Location\",\"WindGustDir\", \"WindDir9am\"]\n",
    "num_data, meta_data = pd.factorize(accomodation_data)\n",
    "print(meta_data)\n",
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old shape: (142193, 24)\n",
      "Index(['Adelaide', 'Albany', 'Albury', 'AliceSprings', 'BadgerysCreek',\n",
      "       'Ballarat', 'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar',\n",
      "       'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart',\n",
      "       'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport', 'Mildura',\n",
      "       'Moree', 'MountGambier', 'MountGinini', 'Newcastle', 'Nhil',\n",
      "       'NorahHead', 'NorfolkIsland', 'Nuriootpa', 'PearceRAAF', 'Penrith',\n",
      "       'Perth', 'PerthAirport', 'Portland', 'Richmond', 'Sale', 'SalmonGums',\n",
      "       'Sydney', 'SydneyAirport', 'Townsville', 'Tuggeranong', 'Uluru',\n",
      "       'WaggaWagga', 'Walpole', 'Watsonia', 'Williamtown', 'Witchcliffe',\n",
      "       'Wollongong', 'Woomera'],\n",
      "      dtype='object')\n",
      "        Adelaide  Albany  Albury  AliceSprings  BadgerysCreek  Ballarat  \\\n",
      "0              0       0       1             0              0         0   \n",
      "1              0       0       1             0              0         0   \n",
      "2              0       0       1             0              0         0   \n",
      "3              0       0       1             0              0         0   \n",
      "4              0       0       1             0              0         0   \n",
      "...          ...     ...     ...           ...            ...       ...   \n",
      "142188         0       0       0             0              0         0   \n",
      "142189         0       0       0             0              0         0   \n",
      "142190         0       0       0             0              0         0   \n",
      "142191         0       0       0             0              0         0   \n",
      "142192         0       0       0             0              0         0   \n",
      "\n",
      "        Bendigo  Brisbane  Cairns  Canberra  ...  Townsville  Tuggeranong  \\\n",
      "0             0         0       0         0  ...           0            0   \n",
      "1             0         0       0         0  ...           0            0   \n",
      "2             0         0       0         0  ...           0            0   \n",
      "3             0         0       0         0  ...           0            0   \n",
      "4             0         0       0         0  ...           0            0   \n",
      "...         ...       ...     ...       ...  ...         ...          ...   \n",
      "142188        0         0       0         0  ...           0            0   \n",
      "142189        0         0       0         0  ...           0            0   \n",
      "142190        0         0       0         0  ...           0            0   \n",
      "142191        0         0       0         0  ...           0            0   \n",
      "142192        0         0       0         0  ...           0            0   \n",
      "\n",
      "        Uluru  WaggaWagga  Walpole  Watsonia  Williamtown  Witchcliffe  \\\n",
      "0           0           0        0         0            0            0   \n",
      "1           0           0        0         0            0            0   \n",
      "2           0           0        0         0            0            0   \n",
      "3           0           0        0         0            0            0   \n",
      "4           0           0        0         0            0            0   \n",
      "...       ...         ...      ...       ...          ...          ...   \n",
      "142188      1           0        0         0            0            0   \n",
      "142189      1           0        0         0            0            0   \n",
      "142190      1           0        0         0            0            0   \n",
      "142191      1           0        0         0            0            0   \n",
      "142192      1           0        0         0            0            0   \n",
      "\n",
      "        Wollongong  Woomera  \n",
      "0                0        0  \n",
      "1                0        0  \n",
      "2                0        0  \n",
      "3                0        0  \n",
      "4                0        0  \n",
      "...            ...      ...  \n",
      "142188           0        0  \n",
      "142189           0        0  \n",
      "142190           0        0  \n",
      "142191           0        0  \n",
      "142192           0        0  \n",
      "\n",
      "[142193 rows x 49 columns]\n",
      "new shape: (142193, 73)\n",
      "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
      "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
      "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
      "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
      "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
      "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
      "...            ...      ...      ...      ...       ...          ...   \n",
      "142188  2017-06-20    Uluru      3.5     21.8       0.0          NaN   \n",
      "142189  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
      "142190  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
      "142191  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
      "142192  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
      "\n",
      "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Townsville  \\\n",
      "0            NaN           W           44.0          W  ...          0   \n",
      "1            NaN         WNW           44.0        NNW  ...          0   \n",
      "2            NaN         WSW           46.0          W  ...          0   \n",
      "3            NaN          NE           24.0         SE  ...          0   \n",
      "4            NaN           W           41.0        ENE  ...          0   \n",
      "...          ...         ...            ...        ...  ...        ...   \n",
      "142188       NaN           E           31.0        ESE  ...          0   \n",
      "142189       NaN           E           31.0         SE  ...          0   \n",
      "142190       NaN         NNW           22.0         SE  ...          0   \n",
      "142191       NaN           N           37.0         SE  ...          0   \n",
      "142192       NaN          SE           28.0        SSE  ...          0   \n",
      "\n",
      "        Tuggeranong  Uluru  WaggaWagga  Walpole  Watsonia  Williamtown  \\\n",
      "0                 0      0           0        0         0            0   \n",
      "1                 0      0           0        0         0            0   \n",
      "2                 0      0           0        0         0            0   \n",
      "3                 0      0           0        0         0            0   \n",
      "4                 0      0           0        0         0            0   \n",
      "...             ...    ...         ...      ...       ...          ...   \n",
      "142188            0      1           0        0         0            0   \n",
      "142189            0      1           0        0         0            0   \n",
      "142190            0      1           0        0         0            0   \n",
      "142191            0      1           0        0         0            0   \n",
      "142192            0      1           0        0         0            0   \n",
      "\n",
      "        Witchcliffe  Wollongong  Woomera  \n",
      "0                 0           0        0  \n",
      "1                 0           0        0  \n",
      "2                 0           0        0  \n",
      "3                 0           0        0  \n",
      "4                 0           0        0  \n",
      "...             ...         ...      ...  \n",
      "142188            0           0        0  \n",
      "142189            0           0        0  \n",
      "142190            0           0        0  \n",
      "142191            0           0        0  \n",
      "142192            0           0        0  \n",
      "\n",
      "[142193 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "#you can use one-hot encoding \n",
    "print('old shape:', mydata_weather.shape)\n",
    "new_data=pd.get_dummies(mydata_weather['Location'])\n",
    "new_column_names=new_data.columns\n",
    "print(new_column_names)\n",
    "print(new_data)\n",
    "new_mydata_weather=mydata_weather.copy()\n",
    "new_mydata_weather[new_column_names]=new_data\n",
    "\n",
    "print('new shape:', new_mydata_weather.shape)\n",
    "print(new_mydata_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          2\n",
      "1          2\n",
      "2          2\n",
      "3          2\n",
      "4          2\n",
      "          ..\n",
      "142188    41\n",
      "142189    41\n",
      "142190    41\n",
      "142191    41\n",
      "142192    41\n",
      "Name: Location, Length: 142193, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#you can use label_encoder.fit_transform() function\n",
    "mydata_weather['Location']= label_encoder.fit_transform(mydata_weather['Location'])\n",
    "print(mydata_weather['Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "In this task you work on the \"nsl-kdd-original\" data. The data set containes numerical and categorical featurees. You need to check whether it contains missing values or noisy data, if yes try to handle them. You may need to convert the categoricall data to numericall, so you can use it (later) in the modeling part. This is because some of the classifiers can not suport categroical varaibles. When you have done use the feature selection function to select the most informative features. In the next lab, you will visualize this prepared data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "In this part, there is a function called \"feature_importance()\" which is responsible to select the most 'n' important features from the given data. \n",
    "At this point, it is not necessary to undrstand the feature_importance function. You just need to call the function with the data select the n top feasture. You can tune the numeber of top features to se what will happen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_importance(mydata,top_featurs):\n",
    "    print('feature_selection_IMP started...')\n",
    "    X=mydata.copy()\n",
    "    y=X['label']\n",
    "    #X=X.drop(['target','biweek_send_date','t_chassis'],axis=1).copy()\n",
    "    \n",
    "    model = ExtraTreesClassifier(n_estimators=100)\n",
    "    model.fit(X,y)\n",
    "    model.feature_importances_ #use inbuilt class feature_importances of tree based classifiers\n",
    "    \n",
    "    #plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    #mc=feat_importances.nlargest(30).plot(kind='barh')\n",
    "    mc=feat_importances.nlargest(top_featurs).index\n",
    "    selected_column=np.array(mc)\n",
    "    plt.show()\n",
    "    # Fit, Format, and Return\n",
    "    return selected_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175341, 45)\n"
     ]
    }
   ],
   "source": [
    "#importing the original data with categorical data\n",
    "mydata_NSL_KDD = pd.read_csv('lab2_data/nsl-kdd-original.csv',low_memory=False)\n",
    "mydata_NSL_KDD.head()\n",
    "print(mydata_NSL_KDD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
      "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
      "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
      "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
      "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
      "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
      "\n",
      "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
      "0  ...                 1               1             0           0   \n",
      "1  ...                 1               2             0           0   \n",
      "2  ...                 1               3             0           0   \n",
      "3  ...                 1               3             1           1   \n",
      "4  ...                 1              40             0           0   \n",
      "\n",
      "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
      "0                 0           1           1                0      Normal   \n",
      "1                 0           1           6                0      Normal   \n",
      "2                 0           2           6                0      Normal   \n",
      "3                 0           2           1                0      Normal   \n",
      "4                 0           2          39                0      Normal   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "In total, there are 0 variables with missing values\n"
     ]
    }
   ],
   "source": [
    "print(mydata_NSL_KDD.head())\n",
    "mydata_bpermits=mydata_NSL_KDD.copy()\n",
    "\n",
    "\n",
    "vars_with_missing = []\n",
    "\n",
    "for f in mydata_bpermits.columns:\n",
    "    #missings = mydata[f].isnull().count()\n",
    "    missings = sum(mydata_bpermits[f].isnull())\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/mydata_bpermits.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 0 variables with missing values\n",
      "Before normalization\n",
      "[[1.21478000e-01 6.00000000e+00 4.00000000e+00 ... 2.42956000e+01\n",
      "  8.37500000e+00 3.01775470e+01]\n",
      " [6.49902000e-01 1.40000000e+01 3.80000000e+01 ... 4.99150000e+01\n",
      "  1.54328650e+01 6.14269340e+01]\n",
      " [1.62312900e+00 8.00000000e+00 1.60000000e+01 ... 2.31875571e+02\n",
      "  1.02737203e+02 1.71795869e+04]\n",
      " ...\n",
      " [9.00000000e-06 2.00000000e+00 0.00000000e+00 ... 9.00000000e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.00000000e-06 2.00000000e+00 0.00000000e+00 ... 9.00000000e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.00000000e-06 2.00000000e+00 0.00000000e+00 ... 9.00000000e-03\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "After Normalization\n",
      "[[2.02463370e-03 5.20020801e-04 3.64497904e-04 ... 2.87959811e-04\n",
      "  1.47663416e-04 2.06627593e-05]\n",
      " [1.08317020e-02 1.35205408e-03 3.46273009e-03 ... 5.91609754e-04\n",
      "  2.72103829e-04 4.20594143e-05]\n",
      " [2.70521550e-02 7.28029121e-04 1.45799162e-03 ... 2.74826905e-03\n",
      "  1.81140614e-03 1.17629729e-02]\n",
      " ...\n",
      " [1.50000028e-07 1.04004160e-04 0.00000000e+00 ... 1.06671097e-07\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.50000028e-07 1.04004160e-04 0.00000000e+00 ... 1.06671097e-07\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.50000028e-07 1.04004160e-04 0.00000000e+00 ... 1.06671097e-07\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "mydata_NSL_KDD.head()\n",
    "\n",
    "\"\"\" TODO:\n",
    "1. fix the missing values\n",
    "2. convert and normalize the values\n",
    "\n",
    "\n",
    "Your code should be placed here...\n",
    "\n",
    "3. using the below code you can call the feature selection function and select the 15 most important features\n",
    "#Note: There is error with the auto feature selection code as it throws exception for non numerical rows\n",
    "\n",
    "#top_featurs=15\n",
    "#Sending the full data to the feature selection function\n",
    "#selected_features=feature_importance(mydata_NSL_KDD,top_featurs)\n",
    "#mydata_NSL_KDD=mydata_NSL_KDD[selected_features]\n",
    "#print('selected features: ',mydata_NSL_KDD.columns)\n",
    "\n",
    "Your code should be placed here...\n",
    "\n",
    "\"\"\"\n",
    "#1. There are no missing values/ blanks as per the output \n",
    "mydata_bpermits=mydata_NSL_KDD.copy()\n",
    "\n",
    "\n",
    "vars_with_missing = []\n",
    "\n",
    "for f in mydata_bpermits.columns:\n",
    "    #missings = mydata[f].isnull().count()\n",
    "    missings = sum(mydata_bpermits[f].isnull())\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/mydata_bpermits.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))\n",
    "\n",
    "#2. #Normalization of Numerical Values\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "#select the top 15 numerical features manually\n",
    "features = np.array(mydata_NSL_KDD.loc[:,['dur','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit']])\n",
    "\n",
    "print(\"Before normalization\")\n",
    "print(features)\n",
    "\n",
    "normalized_feature_width = min_max_scaler.fit_transform(features)\n",
    "print(\"After Normalization\")\n",
    "print(normalized_feature_width)\n",
    "\n",
    "#3. using the below code you can call the feature selection function and select the 15 most important features\n",
    "#Note: There is error with the auto feature selection code as it throws exception for non numerical rows, e.g, 'tcp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "__IMPORTANT__ \n",
    "\n",
    "Please complete this Jupyter Notebook file and upload it in the Blackboard before the deadline.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aung Naing Oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
